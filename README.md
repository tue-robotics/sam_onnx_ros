# SAM C++ ONNX implementation

Inspired by SAM NN from meta and Tensor-RT implementation from: https://github.com/hamdiboukamcha/SPEED-SAM-C-TENSORRT.git

## ğŸŒ Overview
A high-performance C++ implementation for SAM (segment anything model) using ONNX and CUDA, optimized for real-time image segmentation tasks.


## ğŸ“¢ Performance

### Warm-Up cost :fire:
    NVIDIA GeForce RTX 3050
    Encoder Cuda warm-up cost 66.875 ms.
    Decoder Cuda warm-up cost 53.87 ms.

 ### Infernce Time

| Component                  | Pre processing | Inference | Post processing |
|----------------------------|----------------| --------- | ----------------|
| **Image Encoder**          |           | ||
| Parameters                  | 5M        |- | -|
| Speed                       | 8ms       | 33.322ms | 0.437ms |
| **Mask Decoder**           |           | ||
| Parameters                  | 3.876M    |- |- |
| Speed                       | 34ms       | 11.176ms | 5.984|
| **Whole Pipeline (Enc+Dec)** |         | | |
| Parameters                  | 9.66M     | -| -|
| Sum of Speed                       | 92.92ms      | - |-  |


## ğŸ“‚ Project Structure
    SPEED-SAM-CPP-TENSORRT/
    â”œâ”€â”€ include
    â”‚   â”œâ”€â”€ config.h          # Model configuration and macros
    â”‚   â”œâ”€â”€ cuda_utils.h      # CUDA utility macros
    â”‚   â”œâ”€â”€ engineTRT.h       # TensorRT engine management
    â”‚   â”œâ”€â”€ logging.h         # Logging utilities
    â”‚   â”œâ”€â”€ macros.h          # API export/import macros
    â”‚   â”œâ”€â”€ speedSam.h        # SpeedSam class definition
    â”‚   â””â”€â”€ utils.h           # Utility functions for image handling
    â”œâ”€â”€ src
    â”‚   â”œâ”€â”€ engineTRT.cpp     # Implementation of the TensorRT engine
    â”‚   â”œâ”€â”€ main.cpp          # Main entry point
    â”‚   â””â”€â”€ speedSam.cpp      # Implementation of the SpeedSam class
    â””â”€â”€ CMakeLists.txt        # CMake configuration

# ğŸš€ Installation
## Compile
    git clone <repo>
    cd sam_onnx_ros
    # Create a build directory and compile
    mkdir build && cd build
    cmake ..
    make -j$(nproc)

Note: Update the CMakeLists.txt with the correct paths for Onnxruntime and OpenCV and Onnx Models (since for TechUnited we keep them on separate repositories).

You can use main.cpp to run the application

## ROS option
    You can also run the code as a catkin package.

## ğŸ“¦ Dependencies
    CUDA: NVIDIA's parallel computing platform
    Onnx: High-performance deep learning inference
    OpenCV: Image processing library
    C++17: Required standard for compilation
